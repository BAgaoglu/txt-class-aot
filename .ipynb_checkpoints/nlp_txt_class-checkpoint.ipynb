{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca702294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e12b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/Users/Bratz/ML_Projects/nlp-with-rnn\" \n",
    "filename = \"aot_script.txt\"\n",
    "path_to_file = os.path.join(base_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c804eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 146486 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af400fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Armin\r\n",
      "(Narration) On that day, humanity remembered… the fear of oppression under them.\r\n",
      "\r\n",
      "(Narration) And we were disgraced to live in these cages we called walls.\r\n",
      "[Scene: On the battlefield of Titans.]\r\n",
      "Shadis\r\n",
      "Everyone, get ready to fight! There\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad756b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "def text_to_int(text):\n",
    "  return np.array([char2idx[c] for c in text])\n",
    "\n",
    "text_as_int = text_to_int(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "259d89ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ﻿Armin\r\n",
      "(Narr\n",
      "Encoded: [79 22 66 61 57 62  1  0  6 35 49 66 66]\n"
     ]
    }
   ],
   "source": [
    "# lets look at how part of our text is encoded\n",
    "print(\"Text:\", text[:13])\n",
    "print(\"Encoded:\", text_to_int(text[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7008eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Armin\r\n",
      "(Narr\n"
     ]
    }
   ],
   "source": [
    "def int_to_text(ints):\n",
    "  try:\n",
    "    ints = ints.numpy()\n",
    "  except:\n",
    "    pass\n",
    "  return ''.join(idx2char[ints])\n",
    "\n",
    "print(int_to_text(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1af6f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100  # length of sequence for a training example\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "928f8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30093cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):  # for the example: hello\n",
    "    input_text = chunk[:-1]  # hell\n",
    "    target_text = chunk[1:]  # ello\n",
    "    return input_text, target_text  # hell, ello\n",
    "\n",
    "dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec402b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "﻿Armin\r\n",
      "(Narration) On that day, humanity remembered… the fear of oppression under them.\r\n",
      "\r\n",
      "(Narrati\n",
      "\n",
      "OUTPUT\n",
      "Armin\r\n",
      "(Narration) On that day, humanity remembered… the fear of oppression under them.\r\n",
      "\r\n",
      "(Narratio\n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "n) And we were disgraced to live in these cages we called walls.\r\n",
      "[Scene: On the battlefield of Tita\n",
      "\n",
      "OUTPUT\n",
      ") And we were disgraced to live in these cages we called walls.\r\n",
      "[Scene: On the battlefield of Titan\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(2):\n",
    "  print(\"\\n\\nEXAMPLE\\n\")\n",
    "  print(\"INPUT\")\n",
    "  print(int_to_text(x))\n",
    "  print(\"\\nOUTPUT\")\n",
    "  print(int_to_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "451b1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "316b0d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           20480     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 80)            82000     \n",
      "=================================================================\n",
      "Total params: 5,349,456\n",
      "Trainable params: 5,349,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd311547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 80) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90b8492c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tf.Tensor(\n",
      "[[[-1.6801679e-03 -9.1022695e-04 -3.7521524e-03 ... -3.0519857e-04\n",
      "    2.4130316e-03  6.0018557e-03]\n",
      "  [-4.4431287e-04  4.2923545e-03 -6.8619387e-04 ... -4.4490267e-03\n",
      "    6.6724680e-03  9.1967117e-03]\n",
      "  [-3.0763452e-03  7.5744116e-03 -9.2594960e-04 ... -3.0065151e-03\n",
      "    9.4967745e-03  7.6483679e-03]\n",
      "  ...\n",
      "  [-6.2802741e-03 -7.2201947e-06 -5.7600546e-03 ... -4.7483733e-03\n",
      "    3.5234271e-03  1.0686280e-02]\n",
      "  [-8.6538438e-03 -4.5345398e-03 -2.6903125e-03 ... -9.0417573e-03\n",
      "   -7.4237841e-04  9.8694861e-03]\n",
      "  [ 2.5310821e-03 -8.7333778e-03 -3.6252548e-03 ... -7.8472793e-03\n",
      "    1.5347449e-03  1.0691929e-02]]\n",
      "\n",
      " [[-3.6126634e-03  2.0606392e-03 -1.0982529e-03 ... -4.4172280e-05\n",
      "    4.6404293e-03 -7.9518434e-04]\n",
      "  [-5.7658344e-03 -2.3434777e-03  1.9416496e-03 ...  1.7526583e-04\n",
      "    5.8665103e-03 -6.8390742e-03]\n",
      "  [-5.8797565e-03 -2.5252926e-03 -3.1793579e-03 ...  2.9028306e-04\n",
      "    7.4480651e-03  1.4002734e-03]\n",
      "  ...\n",
      "  [-4.6969960e-03  2.9260004e-03  6.7600450e-03 ... -1.3013126e-02\n",
      "    4.1455834e-04  9.8969722e-03]\n",
      "  [-7.6854560e-03  3.9815744e-03  4.1916096e-03 ... -1.1349923e-02\n",
      "    4.6557775e-03  7.5649885e-03]\n",
      "  [-3.4488966e-03  3.1210629e-03  5.7614264e-03 ... -5.1310668e-03\n",
      "    1.7823672e-03  2.7713072e-03]]\n",
      "\n",
      " [[-5.8094347e-03 -1.0109805e-03 -4.4260737e-03 ...  5.8114785e-04\n",
      "    1.3989484e-05  2.8138775e-03]\n",
      "  [-7.8593614e-03 -3.9536781e-03 -1.0843790e-03 ...  6.2639383e-04\n",
      "    3.5176084e-03 -4.3790229e-03]\n",
      "  [-1.3075966e-02 -2.7636020e-03 -4.0820604e-03 ... -5.2779284e-04\n",
      "    8.0410261e-03 -5.9146420e-03]\n",
      "  ...\n",
      "  [ 5.6670140e-04 -2.7712933e-03 -1.0959827e-03 ... -3.9294134e-03\n",
      "   -4.4478159e-03  9.5214043e-03]\n",
      "  [-3.6602446e-03 -6.7773624e-03  2.7684986e-03 ... -4.4916482e-03\n",
      "    2.4982891e-04  2.5965259e-03]\n",
      "  [-8.7290797e-03 -1.3434740e-02  6.9022989e-03 ... -3.5840101e-03\n",
      "   -6.6200970e-05  3.8072148e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.5840839e-04  9.8100137e-03 -1.3395923e-04 ...  5.7472044e-04\n",
      "    1.0763621e-04 -2.3328299e-03]\n",
      "  [-1.8658561e-03  6.8627950e-03 -3.5545523e-03 ...  6.9390720e-05\n",
      "    2.9330512e-03  4.1949591e-03]\n",
      "  [-5.1541836e-03  1.8271595e-03  8.9380681e-04 ... -5.4956228e-04\n",
      "    5.6112353e-03 -3.2217936e-03]\n",
      "  ...\n",
      "  [-5.6875753e-03 -3.9881011e-03  1.5356239e-02 ... -4.0030386e-04\n",
      "    5.6593991e-03  2.3398600e-03]\n",
      "  [-9.5569212e-03 -1.8156749e-03  1.1116356e-02 ... -9.9844881e-04\n",
      "    8.5496567e-03  1.6980541e-03]\n",
      "  [-7.1071405e-03  2.7455294e-03  1.0331127e-02 ... -4.7806045e-03\n",
      "    9.9112242e-03  6.7540067e-03]]\n",
      "\n",
      " [[ 7.7534434e-03 -6.2597082e-03 -7.5382262e-04 ...  6.3339277e-04\n",
      "    2.7550207e-03  3.5708465e-03]\n",
      "  [ 4.6002096e-05 -9.1287121e-03  4.2104168e-04 ...  5.7312027e-03\n",
      "    5.5342801e-03 -8.4040762e-04]\n",
      "  [-4.1067461e-03 -1.2527040e-02  1.9141608e-03 ...  4.2127515e-04\n",
      "    1.0711895e-03  1.3151908e-03]\n",
      "  ...\n",
      "  [ 1.1665217e-03  1.3269990e-03  2.8482889e-04 ... -7.7993483e-03\n",
      "   -1.6442691e-03  6.5271198e-03]\n",
      "  [ 8.7095723e-03 -4.6544028e-03  2.4497163e-04 ... -7.1513192e-03\n",
      "    1.5789883e-03  8.8200476e-03]\n",
      "  [ 6.7135808e-03  1.6367789e-03  2.4970421e-03 ... -9.9442080e-03\n",
      "    6.4271260e-03  1.2066709e-02]]\n",
      "\n",
      " [[ 5.3443760e-03  2.9741329e-04 -2.0429513e-03 ...  3.1956746e-03\n",
      "    2.3097158e-04 -1.7278128e-03]\n",
      "  [ 1.6412984e-03 -1.1430933e-03 -5.3876410e-03 ...  2.0972788e-03\n",
      "    2.5397665e-03  3.9092684e-03]\n",
      "  [ 4.6820566e-04 -1.9132748e-03 -6.5777707e-03 ...  2.2839087e-03\n",
      "    8.8888296e-04  2.2179540e-03]\n",
      "  ...\n",
      "  [ 7.2661117e-03 -2.8497167e-03 -2.0799726e-04 ... -8.7885521e-03\n",
      "    8.3753830e-03  1.2825921e-02]\n",
      "  [ 6.9428030e-03  3.1444570e-03  2.1917447e-03 ... -9.9686459e-03\n",
      "    1.1633066e-02  1.4194574e-02]\n",
      "  [ 5.0093224e-03  6.8446388e-04  5.5722585e-03 ... -9.0491697e-03\n",
      "    1.0111757e-02  8.4341550e-03]]], shape=(64, 100, 80), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# we can see that the predicition is an array of 64 arrays, one for each entry in the batch\n",
    "print(len(example_batch_predictions))\n",
    "print(example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b25aa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[[-1.6801679e-03 -9.1022695e-04 -3.7521524e-03 ... -3.0519857e-04\n",
      "   2.4130316e-03  6.0018557e-03]\n",
      " [-4.4431287e-04  4.2923545e-03 -6.8619387e-04 ... -4.4490267e-03\n",
      "   6.6724680e-03  9.1967117e-03]\n",
      " [-3.0763452e-03  7.5744116e-03 -9.2594960e-04 ... -3.0065151e-03\n",
      "   9.4967745e-03  7.6483679e-03]\n",
      " ...\n",
      " [-6.2802741e-03 -7.2201947e-06 -5.7600546e-03 ... -4.7483733e-03\n",
      "   3.5234271e-03  1.0686280e-02]\n",
      " [-8.6538438e-03 -4.5345398e-03 -2.6903125e-03 ... -9.0417573e-03\n",
      "  -7.4237841e-04  9.8694861e-03]\n",
      " [ 2.5310821e-03 -8.7333778e-03 -3.6252548e-03 ... -7.8472793e-03\n",
      "   1.5347449e-03  1.0691929e-02]], shape=(100, 80), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# lets examine one prediction\n",
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)\n",
    "# notice this is a 2d array of length 100, where each interior array is the prediction for the next character at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "739674df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "tf.Tensor(\n",
      "[-1.6801679e-03 -9.1022695e-04 -3.7521524e-03 -8.5485523e-04\n",
      " -7.0624449e-03  5.2872775e-03  4.9120840e-03  2.0191390e-03\n",
      " -5.6195672e-04 -6.4652693e-03 -5.6369947e-03  5.3611943e-03\n",
      " -2.1593465e-04  1.8121543e-03  1.9406830e-03 -1.2919165e-03\n",
      " -2.8582334e-03  9.6266414e-04 -4.3558166e-03  2.7931621e-04\n",
      "  1.9411718e-03  4.9666190e-03  4.0774705e-04 -2.1237261e-03\n",
      "  3.8379696e-03 -4.5118206e-03 -3.5248528e-04  1.8764834e-03\n",
      "  6.2487558e-03  2.1883990e-03  2.4018032e-03  2.3137827e-03\n",
      " -1.8287571e-03  1.5460881e-03  5.0589570e-04  7.5008525e-03\n",
      "  7.0730373e-03 -2.0693685e-03 -3.3818623e-03 -3.7954858e-05\n",
      "  2.5078389e-03 -3.4849383e-03 -3.1522452e-03 -2.8533936e-03\n",
      "  4.2797445e-04  3.6807866e-03 -6.4006671e-03 -5.7912432e-05\n",
      " -2.4317927e-03  1.2152463e-03  2.3144931e-03  8.1563881e-04\n",
      " -1.5886774e-03 -2.6188688e-03  6.3005544e-05  3.3068736e-04\n",
      "  2.5976221e-03 -1.6374866e-04  3.6626286e-03 -7.2324154e-05\n",
      " -1.5779483e-03  7.7555329e-04 -1.3044879e-03  1.5465483e-03\n",
      "  4.3318551e-03  2.1585494e-03  2.8339983e-03  2.2878046e-03\n",
      " -1.4205886e-03  1.9813648e-03 -3.6316062e-03  2.7438919e-03\n",
      "  6.6791107e-03  8.5036369e-04  5.6826434e-04  2.2736264e-03\n",
      "  4.7954037e-03 -3.0519857e-04  2.4130316e-03  6.0018557e-03], shape=(80,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# and finally well look at a prediction at the first timestep\n",
    "time_pred = pred[0]\n",
    "print(len(time_pred))\n",
    "print(time_pred)\n",
    "# and of course its 65 values representing the probabillity of each character occuring next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4206696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"WEP’M!…h?aa%D]MqyCKls)’Ec%m'x5.n3DssiHDcK\\ufeffTre’[SU%n]I’JRgR’S)pOH0uT(C40zkL8,k)Kl4%Q'e“U4neZB’Zm “C]?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)\n",
    "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
    "\n",
    "# now we can reshape that array and convert all the integers to numbers to see the actual characters\n",
    "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
    "predicted_chars = int_to_text(sampled_indices)\n",
    "\n",
    "predicted_chars  # and this is what the model predicted for training sequence 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdf37084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18eadcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaa5e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c01ac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22/22 [==============================] - 39s 2s/step - loss: 3.4721\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 42s 2s/step - loss: 3.1126\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 40s 2s/step - loss: 2.6112\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 41s 2s/step - loss: 2.2994\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 40s 2s/step - loss: 2.1211\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 36s 2s/step - loss: 1.9818\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 37s 2s/step - loss: 1.8698\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 36s 2s/step - loss: 1.7828\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 36s 2s/step - loss: 1.7019\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 38s 2s/step - loss: 1.6390\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 37s 2s/step - loss: 1.5735\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 36s 2s/step - loss: 1.5169\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 37s 2s/step - loss: 1.4608\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 37s 2s/step - loss: 1.4056\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 35s 2s/step - loss: 1.3524\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 35s 2s/step - loss: 1.3067\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 35s 2s/step - loss: 1.2607\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 35s 2s/step - loss: 1.2174\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 37s 2s/step - loss: 1.1710\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 35s 2s/step - loss: 1.1274\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 35s 2s/step - loss: 1.0823\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 35s 2s/step - loss: 1.0402\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 34s 2s/step - loss: 0.9956\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 34s 2s/step - loss: 0.9491\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 34s 2s/step - loss: 0.9030\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 35s 2s/step - loss: 0.8563\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 34s 2s/step - loss: 0.8106\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 36s 2s/step - loss: 0.7636\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 34s 2s/step - loss: 0.7164\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 34s 2s/step - loss: 0.6652\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 34s 2s/step - loss: 0.6234\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - 34s 2s/step - loss: 0.5774\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - 34s 2s/step - loss: 0.5358\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 35s 2s/step - loss: 0.5019\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - 34s 2s/step - loss: 0.4650\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 34s 2s/step - loss: 0.4329\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - 35s 2s/step - loss: 0.4064\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 34s 2s/step - loss: 0.3835\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - 35s 2s/step - loss: 0.3597\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - 34s 2s/step - loss: 0.3395\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 36s 2s/step - loss: 0.3233\n",
      "Epoch 42/50\n",
      "22/22 [==============================] - 36s 2s/step - loss: 0.3076\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 36s 2s/step - loss: 0.2951\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 36s 2s/step - loss: 0.2819\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 36s 2s/step - loss: 0.2716\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 37s 2s/step - loss: 0.2627\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - 36s 2s/step - loss: 0.2552\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 36s 2s/step - loss: 0.2483\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - 37s 2s/step - loss: 0.2395\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 38s 2s/step - loss: 0.2335\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b50ab312",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2893b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 800\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "    \n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8ebf08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type a starting string: kumandan\n",
      "kumandany surve. St’ll all shantes your mom that with me and turns to me!\n",
      "\n",
      "I’m going back, more south District!\n",
      "Shadis\n",
      "Sasha ush… I’m alright.\n",
      "\n",
      "There’s only one talking your mom…… \n",
      "Sh… Hahaard Pixis!\n",
      "\n",
      "Eren...\n",
      "\n",
      "[Scene: Sometime later, at night.]\n",
      "Franz\n",
      "What… No! It’s that?\n",
      "\n",
      "Was happle an eaten protection.\n",
      "\n",
      "(Narration) The ingenuity of these few raised the survival aroming before shomaget in front of Titans are and it… Armin shede out of has all yever nested. We’ve che fundieded wear havades the next sacr, did!\n",
      "Silding with my way prepared to the building.\n",
      "Armin\n",
      "Hey, but even such firepower cluines.\n",
      "\n",
      "The parrison of mankind once again. What are you doing?!\n",
      "Eren\n",
      "We’re withard wather 1\n",
      "Damis, just like a contion: But the stambs splan ofrranished can ver a chance to gut spoitin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inp = input(\"Type a starting string: \")\n",
    "print(generate_text(model, inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfbfa6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
